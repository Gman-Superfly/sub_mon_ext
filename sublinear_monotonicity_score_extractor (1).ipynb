{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dk4GYvhYkczi",
        "outputId": "c5abd845-364e-4315-b989-81a7f3921d58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing Monotonicity Score Function:\n",
            "Monotone series score: 1.000\n",
            "Random series score: 0.968\n",
            "Decreasing series score: 0.899\n",
            "\n",
            "Model Integration:\n",
            "Input data shape: torch.Size([32, 10])\n",
            "Monotonicity scores shape: torch.Size([32])\n",
            "Model output shape: torch.Size([32, 1])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "\n",
        "# ------------------------------\n",
        "# Monotonicity Score Function\n",
        "# ----------------------------\n",
        "\n",
        "def monotonicity_score(input_tensor, epsilon=0.1, seed=None):\n",
        "    \"\"\"\n",
        "    Compute a sublinear monotonicity score for a 1D tensor.\n",
        "\n",
        "    Purpose: Estimates how close a sequence is to being monotone increasing by\n",
        "    sampling a sublinear number of points and checking for violations (where a\n",
        "    later value is less than an earlier one). The score ranges from 0 (highly\n",
        "    non-monotone) to 1 (fully monotone).\n",
        "\n",
        "    Args:\n",
        "        input_tensor (torch.Tensor): 1D tensor of shape (n,) representing a sequence.\n",
        "        epsilon (float): Error tolerance controlling sample size (smaller = more accurate).\n",
        "                         Default is 0.1.\n",
        "        seed (int, optional): Random seed for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "        float: Monotonicity score between 0 and 1.\n",
        "\n",
        "    Why: This function allows us to quantify monotonicity efficiently, which we\n",
        "    can then use as a feature in a neural network.\n",
        "    \"\"\"\n",
        "    # Validate input\n",
        "    if input_tensor.dim() != 1:\n",
        "        raise ValueError(\"Input must be a 1D tensor\")\n",
        "\n",
        "    n = input_tensor.size(0)\n",
        "    if n < 2:\n",
        "        return 1.0  # Sequences of length 0 or 1 are trivially monotone\n",
        "\n",
        "    # Set seed for reproducibility\n",
        "    if seed is not None:\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "    # Determine sample size: O((1/ε) log n) for sublinear complexity\n",
        "    c = 2.0  # Empirical constant (can be tuned)\n",
        "    num_samples = int(math.ceil(c / epsilon * math.log(n)))\n",
        "    num_samples = min(num_samples, n)  # Don’t sample more than sequence length\n",
        "\n",
        "    # Sample random indices and corresponding values\n",
        "    sampled_indices = torch.randperm(n)[:num_samples]\n",
        "    sampled_values = input_tensor[sampled_indices]\n",
        "\n",
        "    # Sort by index to check monotonicity in sequence order\n",
        "    sorted_indices = torch.argsort(sampled_indices)\n",
        "    sampled_indices = sampled_indices[sorted_indices]\n",
        "    sampled_values = sampled_values[sorted_indices]\n",
        "\n",
        "    # Helper function to count violations using binary search\n",
        "    def count_violations(value, idx, values, indices):\n",
        "        \"\"\"\n",
        "        Count how many points to the right of idx have values less than 'value'.\n",
        "\n",
        "        Why: Efficiently identifies monotonicity violations (later value < earlier value).\n",
        "        \"\"\"\n",
        "        left, right = 0, len(values) - 1\n",
        "        violations = 0\n",
        "\n",
        "        while left <= right:\n",
        "            mid = (left + right) // 2\n",
        "            if indices[mid] > idx:  # Check only points to the right\n",
        "                if values[mid] < value:  # Violation found\n",
        "                    violations += 1\n",
        "                    left = mid + 1  # Continue searching right\n",
        "                else:\n",
        "                    right = mid - 1  # Search left\n",
        "            else:\n",
        "                left = mid + 1  # Skip points to the left\n",
        "\n",
        "        return violations\n",
        "\n",
        "    # Calculate total violations\n",
        "    total_violations = 0\n",
        "    total_checks = 0\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        value = sampled_values[i]\n",
        "        idx = sampled_indices[i]\n",
        "        violations = count_violations(value, idx, sampled_values, sampled_indices)\n",
        "        total_violations += violations\n",
        "        total_checks += (num_samples - i - 1)  # Comparisons to remaining points\n",
        "\n",
        "    # Compute score: 1 - (fraction of violations)\n",
        "    score = 1.0 if total_checks == 0 else max(0.0, 1.0 - total_violations / total_checks)\n",
        "    return score\n",
        "\n",
        "# ------------------------------\n",
        "# PyTorch Model Definition\n",
        "# ------------------------------\n",
        "\n",
        "class SimpleModel(nn.Module):\n",
        "    \"\"\"\n",
        "    A simple neural network that incorporates monotonicity scores as features.\n",
        "\n",
        "    Why: Demonstrates how to integrate the monotonicity score into a model by\n",
        "    concatenating it to each sample’s feature vector.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_dim (int): Number of features per sample (excluding mono score).\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # Input dim + 1 because we append the monotonicity score\n",
        "        self.fc = nn.Linear(input_dim + 1, 1)\n",
        "\n",
        "    def forward(self, x, mono_scores):\n",
        "        \"\"\"\n",
        "        Forward pass: Concatenate mono_scores to input features and process.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, input_dim).\n",
        "            mono_scores (torch.Tensor): Tensor of shape (batch_size,) with scores.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor of shape (batch_size, 1).\n",
        "\n",
        "        Why: Concatenates each sample’s mono score to its features, ensuring\n",
        "        dimensional compatibility.\n",
        "        \"\"\"\n",
        "        # Ensure mono_scores matches batch size and add feature dimension\n",
        "        mono_scores = mono_scores.unsqueeze(1)  # Shape: (batch_size, 1)\n",
        "        x = torch.cat([x, mono_scores], dim=1)  # Shape: (batch_size, input_dim + 1)\n",
        "        return self.fc(x)\n",
        "\n",
        "# ------------------------------\n",
        "# Example Usage\n",
        "# ------------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # ------------------\n",
        "    # Test Monotonicity Score\n",
        "    # ------------------\n",
        "    # Generate synthetic sequences to test the function\n",
        "    n = 1000\n",
        "    monotone_series = torch.arange(n, dtype=torch.float32)  # Strictly increasing\n",
        "    random_series = torch.rand(n)  # Random sequence\n",
        "    decreasing_series = torch.flip(monotone_series, dims=[0])  # Strictly decreasing\n",
        "\n",
        "    # Compute scores\n",
        "    epsilon = 0.1  # Error tolerance for sampling\n",
        "    seed = 42  # For reproducibility\n",
        "    score_monotone = monotonicity_score(monotone_series, epsilon, seed)\n",
        "    score_random = monotonicity_score(random_series, epsilon, seed)\n",
        "    score_decreasing = monotonicity_score(decreasing_series, epsilon, seed)\n",
        "\n",
        "    # Display results\n",
        "    print(\"\\nTesting Monotonicity Score Function:\")\n",
        "    print(f\"Monotone series score: {score_monotone:.3f}\")  # Should be ~1.0\n",
        "    print(f\"Random series score: {score_random:.3f}\")      # Should be ~0.5\n",
        "    print(f\"Decreasing series score: {score_decreasing:.3f}\")  # Should be ~0.0\n",
        "\n",
        "    # ------------------\n",
        "    # Integrate with Model\n",
        "    # ------------------\n",
        "    # Create a batch of data (e.g., tabular data or short sequences)\n",
        "    batch_size = 32\n",
        "    seq_length = 10  # Features per sample, assumed to be ordered\n",
        "    data = torch.rand(batch_size, seq_length)  # Shape: (32, 10)\n",
        "\n",
        "    # Compute monotonicity score for each sample’s feature sequence\n",
        "    # Why: We want one score per sample to concatenate as a feature\n",
        "    mono_scores = torch.tensor(\n",
        "        [monotonicity_score(data[i], epsilon) for i in range(batch_size)],\n",
        "        dtype=torch.float32\n",
        "    )  # Shape: (32,)\n",
        "\n",
        "    # Initialize and run the model\n",
        "    model = SimpleModel(seq_length)\n",
        "    output = model(data, mono_scores)\n",
        "\n",
        "    # Verify output\n",
        "    print(\"\\nModel Integration:\")\n",
        "    print(f\"Input data shape: {data.shape}\")           # (32, 10)\n",
        "    print(f\"Monotonicity scores shape: {mono_scores.shape}\")  # (32,)\n",
        "    print(f\"Model output shape: {output.shape}\")      # (32, 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I3sPTkpPlhrz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}